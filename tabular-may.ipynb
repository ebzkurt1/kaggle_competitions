{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-05T14:31:48.397427Z","iopub.execute_input":"2022-05-05T14:31:48.397765Z","iopub.status.idle":"2022-05-05T14:31:53.932524Z","shell.execute_reply.started":"2022-05-05T14:31:48.397685Z","shell.execute_reply":"2022-05-05T14:31:53.931753Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/tabular-playground-series-may-2022/sample_submission.csv\n/kaggle/input/tabular-playground-series-may-2022/train.csv\n/kaggle/input/tabular-playground-series-may-2022/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"sample_submission_dir = '/kaggle/input/tabular-playground-series-may-2022/sample_submission.csv'\ntrain_data_dir = '/kaggle/input/tabular-playground-series-may-2022/train.csv'\ntest_data_dir = '/kaggle/input/tabular-playground-series-may-2022/test.csv'\n\ntrain_df = pd.read_csv(train_data_dir)\ntest_df = pd.read_csv(test_data_dir)\ncombined_df = pd.concat([train_df,test_df])","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:31:55.621864Z","iopub.execute_input":"2022-05-05T14:31:55.622646Z","iopub.status.idle":"2022-05-05T14:32:09.212748Z","shell.execute_reply.started":"2022-05-05T14:31:55.622598Z","shell.execute_reply":"2022-05-05T14:32:09.211999Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"print(\"Train data shape : \", train_df.shape)\nprint(\"Test data shape : \", test_df.shape)\nprint(\"Overall data shape : \",combined_df.shape)\ndisplay(train_df.head())\ndisplay(train_df.info())\ndisplay(train_df.describe().transpose())","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:32:09.214379Z","iopub.execute_input":"2022-05-05T14:32:09.214617Z","iopub.status.idle":"2022-05-05T14:32:10.451255Z","shell.execute_reply.started":"2022-05-05T14:32:09.214582Z","shell.execute_reply":"2022-05-05T14:32:10.450563Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Train data shape :  (900000, 33)\nTest data shape :  (700000, 32)\nOverall data shape :  (1600000, 33)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   id      f_00      f_01      f_02      f_03      f_04      f_05      f_06  \\\n0   0 -1.373246  0.238887 -0.243376  0.567405 -0.647715  0.839326  0.113133   \n1   1  1.697021 -1.710322 -2.230332 -0.545661  1.113173 -1.552175  0.447825   \n2   2  1.681726  0.616746 -1.027689  0.810492 -0.609086  0.113965 -0.708660   \n3   3 -0.118172 -0.587835 -0.804638  2.086822  0.371005 -0.128831 -0.282575   \n4   4  1.148481 -0.176567 -0.664871 -1.101343  0.467875  0.500117  0.407515   \n\n   f_07  f_08  ...      f_22      f_23      f_24      f_25      f_26  \\\n0     1     5  ... -2.540739  0.766952 -2.730628 -0.208177  1.363402   \n1     1     3  ...  2.278315 -0.633658 -1.217077 -3.782194 -0.058316   \n2     1     0  ... -1.385775 -0.520558 -0.009121  2.788536 -3.703488   \n3     3     2  ...  0.572594 -1.653213  1.686035 -2.533098 -0.608601   \n4     3     3  ... -3.912929 -1.430366  2.127649 -3.306784  4.371371   \n\n         f_27        f_28  f_29  f_30  target  \n0  ABABDADBAB   67.609153     0     0       0  \n1  ACACCADCEB  377.096415     0     0       1  \n2  AAAEABCKAD -195.599702     0     2       1  \n3  BDBBAACBCB  210.826205     0     0       1  \n4  BDBCBBCHFE -217.211798     0     1       1  \n\n[5 rows x 33 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>f_00</th>\n      <th>f_01</th>\n      <th>f_02</th>\n      <th>f_03</th>\n      <th>f_04</th>\n      <th>f_05</th>\n      <th>f_06</th>\n      <th>f_07</th>\n      <th>f_08</th>\n      <th>...</th>\n      <th>f_22</th>\n      <th>f_23</th>\n      <th>f_24</th>\n      <th>f_25</th>\n      <th>f_26</th>\n      <th>f_27</th>\n      <th>f_28</th>\n      <th>f_29</th>\n      <th>f_30</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>-1.373246</td>\n      <td>0.238887</td>\n      <td>-0.243376</td>\n      <td>0.567405</td>\n      <td>-0.647715</td>\n      <td>0.839326</td>\n      <td>0.113133</td>\n      <td>1</td>\n      <td>5</td>\n      <td>...</td>\n      <td>-2.540739</td>\n      <td>0.766952</td>\n      <td>-2.730628</td>\n      <td>-0.208177</td>\n      <td>1.363402</td>\n      <td>ABABDADBAB</td>\n      <td>67.609153</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1.697021</td>\n      <td>-1.710322</td>\n      <td>-2.230332</td>\n      <td>-0.545661</td>\n      <td>1.113173</td>\n      <td>-1.552175</td>\n      <td>0.447825</td>\n      <td>1</td>\n      <td>3</td>\n      <td>...</td>\n      <td>2.278315</td>\n      <td>-0.633658</td>\n      <td>-1.217077</td>\n      <td>-3.782194</td>\n      <td>-0.058316</td>\n      <td>ACACCADCEB</td>\n      <td>377.096415</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1.681726</td>\n      <td>0.616746</td>\n      <td>-1.027689</td>\n      <td>0.810492</td>\n      <td>-0.609086</td>\n      <td>0.113965</td>\n      <td>-0.708660</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>-1.385775</td>\n      <td>-0.520558</td>\n      <td>-0.009121</td>\n      <td>2.788536</td>\n      <td>-3.703488</td>\n      <td>AAAEABCKAD</td>\n      <td>-195.599702</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>-0.118172</td>\n      <td>-0.587835</td>\n      <td>-0.804638</td>\n      <td>2.086822</td>\n      <td>0.371005</td>\n      <td>-0.128831</td>\n      <td>-0.282575</td>\n      <td>3</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0.572594</td>\n      <td>-1.653213</td>\n      <td>1.686035</td>\n      <td>-2.533098</td>\n      <td>-0.608601</td>\n      <td>BDBBAACBCB</td>\n      <td>210.826205</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1.148481</td>\n      <td>-0.176567</td>\n      <td>-0.664871</td>\n      <td>-1.101343</td>\n      <td>0.467875</td>\n      <td>0.500117</td>\n      <td>0.407515</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>-3.912929</td>\n      <td>-1.430366</td>\n      <td>2.127649</td>\n      <td>-3.306784</td>\n      <td>4.371371</td>\n      <td>BDBCBBCHFE</td>\n      <td>-217.211798</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 33 columns</p>\n</div>"},"metadata":{}},{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 900000 entries, 0 to 899999\nData columns (total 33 columns):\n #   Column  Non-Null Count   Dtype  \n---  ------  --------------   -----  \n 0   id      900000 non-null  int64  \n 1   f_00    900000 non-null  float64\n 2   f_01    900000 non-null  float64\n 3   f_02    900000 non-null  float64\n 4   f_03    900000 non-null  float64\n 5   f_04    900000 non-null  float64\n 6   f_05    900000 non-null  float64\n 7   f_06    900000 non-null  float64\n 8   f_07    900000 non-null  int64  \n 9   f_08    900000 non-null  int64  \n 10  f_09    900000 non-null  int64  \n 11  f_10    900000 non-null  int64  \n 12  f_11    900000 non-null  int64  \n 13  f_12    900000 non-null  int64  \n 14  f_13    900000 non-null  int64  \n 15  f_14    900000 non-null  int64  \n 16  f_15    900000 non-null  int64  \n 17  f_16    900000 non-null  int64  \n 18  f_17    900000 non-null  int64  \n 19  f_18    900000 non-null  int64  \n 20  f_19    900000 non-null  float64\n 21  f_20    900000 non-null  float64\n 22  f_21    900000 non-null  float64\n 23  f_22    900000 non-null  float64\n 24  f_23    900000 non-null  float64\n 25  f_24    900000 non-null  float64\n 26  f_25    900000 non-null  float64\n 27  f_26    900000 non-null  float64\n 28  f_27    900000 non-null  object \n 29  f_28    900000 non-null  float64\n 30  f_29    900000 non-null  int64  \n 31  f_30    900000 non-null  int64  \n 32  target  900000 non-null  int64  \ndtypes: float64(16), int64(16), object(1)\nmemory usage: 226.6+ MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"None"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"           count           mean            std          min            25%  \\\nid      900000.0  449999.500000  259807.765473     0.000000  224999.750000   \nf_00    900000.0      -0.000286       0.998888    -4.599856      -0.675490   \nf_01    900000.0       0.001165       0.999193    -4.682199      -0.675162   \nf_02    900000.0       0.001174       1.000514    -4.642676      -0.674369   \nf_03    900000.0      -0.001368       1.000175    -4.658816      -0.676114   \nf_04    900000.0      -0.000571       1.000167    -4.748501      -0.675909   \nf_05    900000.0       0.000284       0.999875    -4.750214      -0.673437   \nf_06    900000.0      -0.000709       0.999942    -4.842919      -0.674876   \nf_07    900000.0       2.031460       1.656172     0.000000       1.000000   \nf_08    900000.0       2.057998       1.590955     0.000000       1.000000   \nf_09    900000.0       2.362431       1.637706     0.000000       1.000000   \nf_10    900000.0       2.177637       1.645953     0.000000       1.000000   \nf_11    900000.0       1.803392       1.537487     0.000000       1.000000   \nf_12    900000.0       2.842373       1.762835     0.000000       2.000000   \nf_13    900000.0       2.239778       1.538426     0.000000       1.000000   \nf_14    900000.0       1.514686       1.359213     0.000000       0.000000   \nf_15    900000.0       2.101132       1.569093     0.000000       1.000000   \nf_16    900000.0       2.096713       1.560169     0.000000       1.000000   \nf_17    900000.0       1.858518       1.467675     0.000000       1.000000   \nf_18    900000.0       2.065131       1.564783     0.000000       1.000000   \nf_19    900000.0       0.308713       2.316026   -11.280941      -1.236061   \nf_20    900000.0      -0.178730       2.400494   -11.257917      -1.804612   \nf_21    900000.0      -0.156307       2.484706   -13.310146      -1.820063   \nf_22    900000.0      -0.009273       2.450797   -11.853530      -1.645585   \nf_23    900000.0      -0.369459       2.453405   -12.301097      -2.019739   \nf_24    900000.0      -0.342738       2.386941   -11.416189      -1.955956   \nf_25    900000.0       0.176549       2.416959   -11.918306      -1.440424   \nf_26    900000.0       0.357591       2.476020   -14.300577      -1.261598   \nf_28    900000.0      -0.380876     238.773054 -1229.753052    -159.427418   \nf_29    900000.0       0.345661       0.475584     0.000000       0.000000   \nf_30    900000.0       1.002654       0.818989     0.000000       0.000000   \ntarget  900000.0       0.486488       0.499818     0.000000       0.000000   \n\n                  50%            75%            max  \nid      449999.500000  674999.250000  899999.000000  \nf_00         0.001144       0.674337       4.749301  \nf_01         0.002014       0.675021       4.815699  \nf_02         0.002218       0.677505       4.961982  \nf_03        -0.002227       0.672544       4.454920  \nf_04        -0.001662       0.673789       4.948983  \nf_05        -0.000438       0.675028       4.971881  \nf_06        -0.001492       0.674749       4.822668  \nf_07         2.000000       3.000000      15.000000  \nf_08         2.000000       3.000000      16.000000  \nf_09         2.000000       3.000000      14.000000  \nf_10         2.000000       3.000000      14.000000  \nf_11         2.000000       3.000000      13.000000  \nf_12         3.000000       4.000000      16.000000  \nf_13         2.000000       3.000000      12.000000  \nf_14         1.000000       2.000000      14.000000  \nf_15         2.000000       3.000000      14.000000  \nf_16         2.000000       3.000000      15.000000  \nf_17         2.000000       3.000000      14.000000  \nf_18         2.000000       3.000000      13.000000  \nf_19         0.330249       1.880517      12.079667  \nf_20        -0.190571       1.444508      11.475325  \nf_21        -0.152668       1.507071      14.455426  \nf_22         0.030850       1.661676      11.344080  \nf_23        -0.390966       1.255408      12.247100  \nf_24        -0.340746       1.266673      12.389844  \nf_25         0.160912       1.795928      12.529179  \nf_26         0.404212       2.028219      12.913041  \nf_28        -0.519808     158.987357    1229.562577  \nf_29         0.000000       1.000000       1.000000  \nf_30         1.000000       2.000000       2.000000  \ntarget       0.000000       1.000000       1.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>id</th>\n      <td>900000.0</td>\n      <td>449999.500000</td>\n      <td>259807.765473</td>\n      <td>0.000000</td>\n      <td>224999.750000</td>\n      <td>449999.500000</td>\n      <td>674999.250000</td>\n      <td>899999.000000</td>\n    </tr>\n    <tr>\n      <th>f_00</th>\n      <td>900000.0</td>\n      <td>-0.000286</td>\n      <td>0.998888</td>\n      <td>-4.599856</td>\n      <td>-0.675490</td>\n      <td>0.001144</td>\n      <td>0.674337</td>\n      <td>4.749301</td>\n    </tr>\n    <tr>\n      <th>f_01</th>\n      <td>900000.0</td>\n      <td>0.001165</td>\n      <td>0.999193</td>\n      <td>-4.682199</td>\n      <td>-0.675162</td>\n      <td>0.002014</td>\n      <td>0.675021</td>\n      <td>4.815699</td>\n    </tr>\n    <tr>\n      <th>f_02</th>\n      <td>900000.0</td>\n      <td>0.001174</td>\n      <td>1.000514</td>\n      <td>-4.642676</td>\n      <td>-0.674369</td>\n      <td>0.002218</td>\n      <td>0.677505</td>\n      <td>4.961982</td>\n    </tr>\n    <tr>\n      <th>f_03</th>\n      <td>900000.0</td>\n      <td>-0.001368</td>\n      <td>1.000175</td>\n      <td>-4.658816</td>\n      <td>-0.676114</td>\n      <td>-0.002227</td>\n      <td>0.672544</td>\n      <td>4.454920</td>\n    </tr>\n    <tr>\n      <th>f_04</th>\n      <td>900000.0</td>\n      <td>-0.000571</td>\n      <td>1.000167</td>\n      <td>-4.748501</td>\n      <td>-0.675909</td>\n      <td>-0.001662</td>\n      <td>0.673789</td>\n      <td>4.948983</td>\n    </tr>\n    <tr>\n      <th>f_05</th>\n      <td>900000.0</td>\n      <td>0.000284</td>\n      <td>0.999875</td>\n      <td>-4.750214</td>\n      <td>-0.673437</td>\n      <td>-0.000438</td>\n      <td>0.675028</td>\n      <td>4.971881</td>\n    </tr>\n    <tr>\n      <th>f_06</th>\n      <td>900000.0</td>\n      <td>-0.000709</td>\n      <td>0.999942</td>\n      <td>-4.842919</td>\n      <td>-0.674876</td>\n      <td>-0.001492</td>\n      <td>0.674749</td>\n      <td>4.822668</td>\n    </tr>\n    <tr>\n      <th>f_07</th>\n      <td>900000.0</td>\n      <td>2.031460</td>\n      <td>1.656172</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>15.000000</td>\n    </tr>\n    <tr>\n      <th>f_08</th>\n      <td>900000.0</td>\n      <td>2.057998</td>\n      <td>1.590955</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>16.000000</td>\n    </tr>\n    <tr>\n      <th>f_09</th>\n      <td>900000.0</td>\n      <td>2.362431</td>\n      <td>1.637706</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>14.000000</td>\n    </tr>\n    <tr>\n      <th>f_10</th>\n      <td>900000.0</td>\n      <td>2.177637</td>\n      <td>1.645953</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>14.000000</td>\n    </tr>\n    <tr>\n      <th>f_11</th>\n      <td>900000.0</td>\n      <td>1.803392</td>\n      <td>1.537487</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>13.000000</td>\n    </tr>\n    <tr>\n      <th>f_12</th>\n      <td>900000.0</td>\n      <td>2.842373</td>\n      <td>1.762835</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>4.000000</td>\n      <td>16.000000</td>\n    </tr>\n    <tr>\n      <th>f_13</th>\n      <td>900000.0</td>\n      <td>2.239778</td>\n      <td>1.538426</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>12.000000</td>\n    </tr>\n    <tr>\n      <th>f_14</th>\n      <td>900000.0</td>\n      <td>1.514686</td>\n      <td>1.359213</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>14.000000</td>\n    </tr>\n    <tr>\n      <th>f_15</th>\n      <td>900000.0</td>\n      <td>2.101132</td>\n      <td>1.569093</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>14.000000</td>\n    </tr>\n    <tr>\n      <th>f_16</th>\n      <td>900000.0</td>\n      <td>2.096713</td>\n      <td>1.560169</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>15.000000</td>\n    </tr>\n    <tr>\n      <th>f_17</th>\n      <td>900000.0</td>\n      <td>1.858518</td>\n      <td>1.467675</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>14.000000</td>\n    </tr>\n    <tr>\n      <th>f_18</th>\n      <td>900000.0</td>\n      <td>2.065131</td>\n      <td>1.564783</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>13.000000</td>\n    </tr>\n    <tr>\n      <th>f_19</th>\n      <td>900000.0</td>\n      <td>0.308713</td>\n      <td>2.316026</td>\n      <td>-11.280941</td>\n      <td>-1.236061</td>\n      <td>0.330249</td>\n      <td>1.880517</td>\n      <td>12.079667</td>\n    </tr>\n    <tr>\n      <th>f_20</th>\n      <td>900000.0</td>\n      <td>-0.178730</td>\n      <td>2.400494</td>\n      <td>-11.257917</td>\n      <td>-1.804612</td>\n      <td>-0.190571</td>\n      <td>1.444508</td>\n      <td>11.475325</td>\n    </tr>\n    <tr>\n      <th>f_21</th>\n      <td>900000.0</td>\n      <td>-0.156307</td>\n      <td>2.484706</td>\n      <td>-13.310146</td>\n      <td>-1.820063</td>\n      <td>-0.152668</td>\n      <td>1.507071</td>\n      <td>14.455426</td>\n    </tr>\n    <tr>\n      <th>f_22</th>\n      <td>900000.0</td>\n      <td>-0.009273</td>\n      <td>2.450797</td>\n      <td>-11.853530</td>\n      <td>-1.645585</td>\n      <td>0.030850</td>\n      <td>1.661676</td>\n      <td>11.344080</td>\n    </tr>\n    <tr>\n      <th>f_23</th>\n      <td>900000.0</td>\n      <td>-0.369459</td>\n      <td>2.453405</td>\n      <td>-12.301097</td>\n      <td>-2.019739</td>\n      <td>-0.390966</td>\n      <td>1.255408</td>\n      <td>12.247100</td>\n    </tr>\n    <tr>\n      <th>f_24</th>\n      <td>900000.0</td>\n      <td>-0.342738</td>\n      <td>2.386941</td>\n      <td>-11.416189</td>\n      <td>-1.955956</td>\n      <td>-0.340746</td>\n      <td>1.266673</td>\n      <td>12.389844</td>\n    </tr>\n    <tr>\n      <th>f_25</th>\n      <td>900000.0</td>\n      <td>0.176549</td>\n      <td>2.416959</td>\n      <td>-11.918306</td>\n      <td>-1.440424</td>\n      <td>0.160912</td>\n      <td>1.795928</td>\n      <td>12.529179</td>\n    </tr>\n    <tr>\n      <th>f_26</th>\n      <td>900000.0</td>\n      <td>0.357591</td>\n      <td>2.476020</td>\n      <td>-14.300577</td>\n      <td>-1.261598</td>\n      <td>0.404212</td>\n      <td>2.028219</td>\n      <td>12.913041</td>\n    </tr>\n    <tr>\n      <th>f_28</th>\n      <td>900000.0</td>\n      <td>-0.380876</td>\n      <td>238.773054</td>\n      <td>-1229.753052</td>\n      <td>-159.427418</td>\n      <td>-0.519808</td>\n      <td>158.987357</td>\n      <td>1229.562577</td>\n    </tr>\n    <tr>\n      <th>f_29</th>\n      <td>900000.0</td>\n      <td>0.345661</td>\n      <td>0.475584</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>f_30</th>\n      <td>900000.0</td>\n      <td>1.002654</td>\n      <td>0.818989</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>target</th>\n      <td>900000.0</td>\n      <td>0.486488</td>\n      <td>0.499818</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"for column in combined_df.columns:\n    print(f\"Number of unique elements in column {column} : \", combined_df[column].nunique())","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:32:10.452316Z","iopub.execute_input":"2022-05-05T14:32:10.453168Z","iopub.status.idle":"2022-05-05T14:32:13.447146Z","shell.execute_reply.started":"2022-05-05T14:32:10.453127Z","shell.execute_reply":"2022-05-05T14:32:13.446183Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Number of unique elements in column id :  1600000\nNumber of unique elements in column f_00 :  1600000\nNumber of unique elements in column f_01 :  1600000\nNumber of unique elements in column f_02 :  1600000\nNumber of unique elements in column f_03 :  1600000\nNumber of unique elements in column f_04 :  1600000\nNumber of unique elements in column f_05 :  1600000\nNumber of unique elements in column f_06 :  1600000\nNumber of unique elements in column f_07 :  17\nNumber of unique elements in column f_08 :  16\nNumber of unique elements in column f_09 :  16\nNumber of unique elements in column f_10 :  16\nNumber of unique elements in column f_11 :  15\nNumber of unique elements in column f_12 :  17\nNumber of unique elements in column f_13 :  14\nNumber of unique elements in column f_14 :  14\nNumber of unique elements in column f_15 :  15\nNumber of unique elements in column f_16 :  16\nNumber of unique elements in column f_17 :  15\nNumber of unique elements in column f_18 :  14\nNumber of unique elements in column f_19 :  1600000\nNumber of unique elements in column f_20 :  1600000\nNumber of unique elements in column f_21 :  1600000\nNumber of unique elements in column f_22 :  1600000\nNumber of unique elements in column f_23 :  1600000\nNumber of unique elements in column f_24 :  1600000\nNumber of unique elements in column f_25 :  1600000\nNumber of unique elements in column f_26 :  1600000\nNumber of unique elements in column f_27 :  1181880\nNumber of unique elements in column f_28 :  1600000\nNumber of unique elements in column f_29 :  2\nNumber of unique elements in column f_30 :  3\nNumber of unique elements in column target :  2\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_df['f_27'].str.split('',expand=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:32:13.449718Z","iopub.execute_input":"2022-05-05T14:32:13.450038Z","iopub.status.idle":"2022-05-05T14:32:21.098550Z","shell.execute_reply.started":"2022-05-05T14:32:13.449981Z","shell.execute_reply":"2022-05-05T14:32:21.097884Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"       0  1  2  3  4  5  6  7  8  9  10 11\n0          A  B  A  B  D  A  D  B  A  B   \n1          A  C  A  C  C  A  D  C  E  B   \n2          A  A  A  E  A  B  C  K  A  D   \n3          B  D  B  B  A  A  C  B  C  B   \n4          B  D  B  C  B  B  C  H  F  E   \n...    .. .. .. .. .. .. .. .. .. .. .. ..\n699995     B  C  B  C  E  B  H  M  C  D   \n699996     B  A  A  B  C  A  D  Q  F  C   \n699997     A  A  A  J  C  B  G  Q  B  A   \n699998     B  C  B  B  C  A  B  N  D  E   \n699999     A  F  B  E  B  A  C  H  F  F   \n\n[1600000 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>A</td>\n      <td>B</td>\n      <td>A</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>D</td>\n      <td>B</td>\n      <td>A</td>\n      <td>B</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>A</td>\n      <td>C</td>\n      <td>A</td>\n      <td>C</td>\n      <td>C</td>\n      <td>A</td>\n      <td>D</td>\n      <td>C</td>\n      <td>E</td>\n      <td>B</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>E</td>\n      <td>A</td>\n      <td>B</td>\n      <td>C</td>\n      <td>K</td>\n      <td>A</td>\n      <td>D</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>B</td>\n      <td>D</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>C</td>\n      <td>B</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>B</td>\n      <td>D</td>\n      <td>B</td>\n      <td>C</td>\n      <td>B</td>\n      <td>B</td>\n      <td>C</td>\n      <td>H</td>\n      <td>F</td>\n      <td>E</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>699995</th>\n      <td></td>\n      <td>B</td>\n      <td>C</td>\n      <td>B</td>\n      <td>C</td>\n      <td>E</td>\n      <td>B</td>\n      <td>H</td>\n      <td>M</td>\n      <td>C</td>\n      <td>D</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>699996</th>\n      <td></td>\n      <td>B</td>\n      <td>A</td>\n      <td>A</td>\n      <td>B</td>\n      <td>C</td>\n      <td>A</td>\n      <td>D</td>\n      <td>Q</td>\n      <td>F</td>\n      <td>C</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>699997</th>\n      <td></td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>J</td>\n      <td>C</td>\n      <td>B</td>\n      <td>G</td>\n      <td>Q</td>\n      <td>B</td>\n      <td>A</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>699998</th>\n      <td></td>\n      <td>B</td>\n      <td>C</td>\n      <td>B</td>\n      <td>B</td>\n      <td>C</td>\n      <td>A</td>\n      <td>B</td>\n      <td>N</td>\n      <td>D</td>\n      <td>E</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>699999</th>\n      <td></td>\n      <td>A</td>\n      <td>F</td>\n      <td>B</td>\n      <td>E</td>\n      <td>B</td>\n      <td>A</td>\n      <td>C</td>\n      <td>H</td>\n      <td>F</td>\n      <td>F</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n<p>1600000 rows × 12 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"numerical_column_names = [c for c in combined_df.columns if combined_df[c].nunique()>20 if c not in(['id','target', 'f_27'])]\n        \nf_27_label_encoders = {}        \nf_27_expanded = combined_df['f_27'].str.split('',expand=True)\n\nfor column in f_27_expanded.columns:\n    if column != 0 and column != 11:\n        temp_encoder = LabelEncoder() # Initialize temporary encoders\n        temp_encoder.fit(f_27_expanded[column])\n        temp_name = f'f_27_{column}'\n        f_27_label_encoders[temp_name] = temp_encoder\n        \nnumerical_columns = combined_df[numerical_column_names]\nscaler = StandardScaler()\nscaler.fit(numerical_columns)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:32:21.099878Z","iopub.execute_input":"2022-05-05T14:32:21.100138Z","iopub.status.idle":"2022-05-05T14:32:32.140252Z","shell.execute_reply.started":"2022-05-05T14:32:21.100103Z","shell.execute_reply":"2022-05-05T14:32:32.139383Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"StandardScaler()"},"metadata":{}}]},{"cell_type":"code","source":"def memory_reduce(df):\n    for col in df.columns:\n        col_type = df[col].dtype\n        if col_type != 'object' and col_type != \"datetime64[ns]\":\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:32:32.141614Z","iopub.execute_input":"2022-05-05T14:32:32.142448Z","iopub.status.idle":"2022-05-05T14:32:32.155778Z","shell.execute_reply.started":"2022-05-05T14:32:32.142403Z","shell.execute_reply":"2022-05-05T14:32:32.154706Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def data_process(\n    data,\n    numerical_column_names=numerical_column_names,\n    f_27_encoders=None,\n    scaler=None,\n    val_split=True,\n    val_split_ratio=0.2,\n    encode=True,\n    standardize=True,\n    shrink=True,\n    drop_encoded=True,\n):\n    print(data.columns)\n    if encode:\n        expanded_f_27 = data['f_27'].str.split('',expand=True)\n        for column in expanded_f_27.columns:\n            if column != 0 and column != 11:\n                data[f'f_27_{column}'] = f_27_encoders[f'f_27_{column}'].transform(expanded_f_27[column])\n        if drop_encoded:\n            data = data.drop('f_27',axis=1)\n    if standardize:\n        data[numerical_column_names] = scaler.transform(data[numerical_column_names])\n    if shrink:\n        data = memory_reduce(data)\n    \n    y = data['target']\n    X = data.drop(['id','target'],axis=1)\n    if val_split:\n        X_train, X_val, y_train, y_val = train_test_split(\n            X, y, test_size=val_split_ratio, random_state=1)\n        return X_train, X_val, y_train, y_val\n    else:\n        return X, y","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:32:32.157540Z","iopub.execute_input":"2022-05-05T14:32:32.157876Z","iopub.status.idle":"2022-05-05T14:32:32.170854Z","shell.execute_reply.started":"2022-05-05T14:32:32.157830Z","shell.execute_reply":"2022-05-05T14:32:32.169093Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = data_process(\n    data=train_df,\n    f_27_encoders=f_27_label_encoders,\n    scaler=scaler,\n)\ndisplay(X_train.head())\ndisplay(X_train.describe().transpose())\ndisplay(X_train.info())","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:32:32.172615Z","iopub.execute_input":"2022-05-05T14:32:32.173787Z","iopub.status.idle":"2022-05-05T14:32:41.046209Z","shell.execute_reply.started":"2022-05-05T14:32:32.173739Z","shell.execute_reply":"2022-05-05T14:32:41.045305Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Index(['id', 'f_00', 'f_01', 'f_02', 'f_03', 'f_04', 'f_05', 'f_06', 'f_07',\n       'f_08', 'f_09', 'f_10', 'f_11', 'f_12', 'f_13', 'f_14', 'f_15', 'f_16',\n       'f_17', 'f_18', 'f_19', 'f_20', 'f_21', 'f_22', 'f_23', 'f_24', 'f_25',\n       'f_26', 'f_27', 'f_28', 'f_29', 'f_30', 'target'],\n      dtype='object')\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"            f_00      f_01      f_02      f_03      f_04      f_05      f_06  \\\n94700   0.695515  0.982312  0.954313  0.096462  0.777448 -0.978963 -1.522706   \n337388  0.268453 -0.013883 -0.967797  0.693565  0.389139 -0.554491 -0.893521   \n714257  1.959106  1.237826  1.866462  2.183901  0.909071  1.497526 -1.793539   \n641220 -0.165790  0.476863 -0.335407  1.214246  0.061892  1.228127  0.938207   \n109997 -0.563624  0.675672  0.369230  0.831257 -1.707643 -2.078516 -1.860021   \n\n        f_07  f_08  f_09  ...  f_27_1  f_27_2  f_27_3  f_27_4  f_27_5  f_27_6  \\\n94700      2     0     3  ...       0       1       1       3       1       1   \n337388     3     1     1  ...       1       2       1       7       0       1   \n714257     3     1     3  ...       1       1       0       1       1       0   \n641220     1     3     7  ...       0       1       1       0       0       0   \n109997     1     5     2  ...       1       0       1       3       0       0   \n\n        f_27_7  f_27_8  f_27_9  f_27_10  \n94700        2       5       1        1  \n337388       3      11       1        1  \n714257       4       1       2        1  \n641220       1      14       5        4  \n109997       0       2       4        2  \n\n[5 rows x 40 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>f_00</th>\n      <th>f_01</th>\n      <th>f_02</th>\n      <th>f_03</th>\n      <th>f_04</th>\n      <th>f_05</th>\n      <th>f_06</th>\n      <th>f_07</th>\n      <th>f_08</th>\n      <th>f_09</th>\n      <th>...</th>\n      <th>f_27_1</th>\n      <th>f_27_2</th>\n      <th>f_27_3</th>\n      <th>f_27_4</th>\n      <th>f_27_5</th>\n      <th>f_27_6</th>\n      <th>f_27_7</th>\n      <th>f_27_8</th>\n      <th>f_27_9</th>\n      <th>f_27_10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>94700</th>\n      <td>0.695515</td>\n      <td>0.982312</td>\n      <td>0.954313</td>\n      <td>0.096462</td>\n      <td>0.777448</td>\n      <td>-0.978963</td>\n      <td>-1.522706</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>337388</th>\n      <td>0.268453</td>\n      <td>-0.013883</td>\n      <td>-0.967797</td>\n      <td>0.693565</td>\n      <td>0.389139</td>\n      <td>-0.554491</td>\n      <td>-0.893521</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>11</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>714257</th>\n      <td>1.959106</td>\n      <td>1.237826</td>\n      <td>1.866462</td>\n      <td>2.183901</td>\n      <td>0.909071</td>\n      <td>1.497526</td>\n      <td>-1.793539</td>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>641220</th>\n      <td>-0.165790</td>\n      <td>0.476863</td>\n      <td>-0.335407</td>\n      <td>1.214246</td>\n      <td>0.061892</td>\n      <td>1.228127</td>\n      <td>0.938207</td>\n      <td>1</td>\n      <td>3</td>\n      <td>7</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>14</td>\n      <td>5</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>109997</th>\n      <td>-0.563624</td>\n      <td>0.675672</td>\n      <td>0.369230</td>\n      <td>0.831257</td>\n      <td>-1.707643</td>\n      <td>-2.078516</td>\n      <td>-1.860021</td>\n      <td>1</td>\n      <td>5</td>\n      <td>2</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>4</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 40 columns</p>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"            count      mean       std       min       25%       50%  \\\nf_00     720000.0  0.000240  0.999180 -4.602006 -0.674705  0.002412   \nf_01     720000.0  0.001097  1.001189 -4.690551 -0.676137  0.002233   \nf_02     720000.0  0.000616  1.000379 -4.641183 -0.674361  0.001693   \nf_03     720000.0 -0.001472  0.999500 -4.624012 -0.676358 -0.001636   \nf_04     720000.0 -0.000920  1.001125 -4.749980 -0.676499 -0.002058   \nf_05     720000.0  0.000403  0.999037 -4.576734 -0.673542 -0.000391   \nf_06     720000.0 -0.001742  1.000329 -4.844773 -0.675401 -0.003064   \nf_07     720000.0  2.032101  1.656758  0.000000  1.000000  2.000000   \nf_08     720000.0  2.058133  1.589792  0.000000  1.000000  2.000000   \nf_09     720000.0  2.362396  1.638384  0.000000  1.000000  2.000000   \nf_10     720000.0  2.178393  1.647363  0.000000  1.000000  2.000000   \nf_11     720000.0  1.803815  1.536798  0.000000  1.000000  2.000000   \nf_12     720000.0  2.842792  1.762582  0.000000  2.000000  3.000000   \nf_13     720000.0  2.239012  1.538853  0.000000  1.000000  2.000000   \nf_14     720000.0  1.515094  1.359418  0.000000  0.000000  1.000000   \nf_15     720000.0  2.100882  1.568964  0.000000  1.000000  2.000000   \nf_16     720000.0  2.095808  1.560076  0.000000  1.000000  2.000000   \nf_17     720000.0  1.859015  1.467834  0.000000  1.000000  2.000000   \nf_18     720000.0  2.063921  1.563454  0.000000  1.000000  2.000000   \nf_19     720000.0  0.000250  1.000247 -5.004879 -0.666936  0.010062   \nf_20     720000.0 -0.000600  1.000388 -4.618396 -0.677958 -0.005689   \nf_21     720000.0 -0.001178  1.000322 -5.294815 -0.671577 -0.000045   \nf_22     720000.0 -0.000726  0.999514 -4.833376 -0.667598  0.015394   \nf_23     720000.0  0.000729  1.000057 -4.835009 -0.672489 -0.008004   \nf_24     720000.0 -0.000332  0.999378 -4.637862 -0.675718  0.000694   \nf_25     720000.0 -0.000380  1.000008 -5.003208 -0.669041 -0.006302   \nf_26     720000.0 -0.000658  0.999808 -5.036366 -0.653386  0.018154   \nf_28     720000.0 -0.001669  0.999937 -5.149409 -0.667938 -0.002385   \nf_29     720000.0  0.345790  0.475626  0.000000  0.000000  0.000000   \nf_30     720000.0  1.003101  0.819145  0.000000  0.000000  1.000000   \nf_27_1   720000.0  0.498760  0.499999  0.000000  0.000000  0.000000   \nf_27_2   720000.0  1.967406  1.500410  0.000000  1.000000  2.000000   \nf_27_3   720000.0  0.668911  0.470605  0.000000  0.000000  1.000000   \nf_27_4   720000.0  1.988535  1.595156  0.000000  1.000000  2.000000   \nf_27_5   720000.0  1.386311  1.297445  0.000000  0.000000  1.000000   \nf_27_6   720000.0  0.467568  0.498947  0.000000  0.000000  0.000000   \nf_27_7   720000.0  2.378196  1.656377  0.000000  1.000000  2.000000   \nf_27_8   720000.0  9.363194  5.704607  0.000000  4.000000  9.000000   \nf_27_9   720000.0  2.022092  1.600362  0.000000  1.000000  2.000000   \nf_27_10  720000.0  2.283601  1.652476  0.000000  1.000000  2.000000   \n\n               75%        max  \nf_00      0.674662   4.751926  \nf_01      0.676277   4.823608  \nf_02      0.676369   4.959370  \nf_03      0.672346   4.451519  \nf_04      0.673101   4.950466  \nf_05      0.674824   4.538604  \nf_06      0.674177   4.823084  \nf_07      3.000000  15.000000  \nf_08      3.000000  16.000000  \nf_09      3.000000  14.000000  \nf_10      3.000000  14.000000  \nf_11      3.000000  13.000000  \nf_12      4.000000  16.000000  \nf_13      3.000000  12.000000  \nf_14      2.000000  14.000000  \nf_15      3.000000  14.000000  \nf_16      3.000000  14.000000  \nf_17      3.000000  14.000000  \nf_18      3.000000  13.000000  \nf_19      0.678778   5.083719  \nf_20      0.676017   4.856252  \nf_21      0.668177   5.880781  \nf_22      0.679953   4.631773  \nf_23      0.662473   5.143642  \nf_24      0.673654   4.812514  \nf_25      0.669827   4.579917  \nf_26      0.674503   5.069536  \nf_28      0.665618   5.148192  \nf_29      1.000000   1.000000  \nf_30      2.000000   2.000000  \nf_27_1    1.000000   1.000000  \nf_27_2    3.000000  13.000000  \nf_27_3    1.000000   1.000000  \nf_27_4    3.000000  14.000000  \nf_27_5    2.000000  14.000000  \nf_27_6    1.000000   1.000000  \nf_27_7    3.000000  14.000000  \nf_27_8   14.000000  19.000000  \nf_27_9    3.000000  14.000000  \nf_27_10   3.000000  14.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>f_00</th>\n      <td>720000.0</td>\n      <td>0.000240</td>\n      <td>0.999180</td>\n      <td>-4.602006</td>\n      <td>-0.674705</td>\n      <td>0.002412</td>\n      <td>0.674662</td>\n      <td>4.751926</td>\n    </tr>\n    <tr>\n      <th>f_01</th>\n      <td>720000.0</td>\n      <td>0.001097</td>\n      <td>1.001189</td>\n      <td>-4.690551</td>\n      <td>-0.676137</td>\n      <td>0.002233</td>\n      <td>0.676277</td>\n      <td>4.823608</td>\n    </tr>\n    <tr>\n      <th>f_02</th>\n      <td>720000.0</td>\n      <td>0.000616</td>\n      <td>1.000379</td>\n      <td>-4.641183</td>\n      <td>-0.674361</td>\n      <td>0.001693</td>\n      <td>0.676369</td>\n      <td>4.959370</td>\n    </tr>\n    <tr>\n      <th>f_03</th>\n      <td>720000.0</td>\n      <td>-0.001472</td>\n      <td>0.999500</td>\n      <td>-4.624012</td>\n      <td>-0.676358</td>\n      <td>-0.001636</td>\n      <td>0.672346</td>\n      <td>4.451519</td>\n    </tr>\n    <tr>\n      <th>f_04</th>\n      <td>720000.0</td>\n      <td>-0.000920</td>\n      <td>1.001125</td>\n      <td>-4.749980</td>\n      <td>-0.676499</td>\n      <td>-0.002058</td>\n      <td>0.673101</td>\n      <td>4.950466</td>\n    </tr>\n    <tr>\n      <th>f_05</th>\n      <td>720000.0</td>\n      <td>0.000403</td>\n      <td>0.999037</td>\n      <td>-4.576734</td>\n      <td>-0.673542</td>\n      <td>-0.000391</td>\n      <td>0.674824</td>\n      <td>4.538604</td>\n    </tr>\n    <tr>\n      <th>f_06</th>\n      <td>720000.0</td>\n      <td>-0.001742</td>\n      <td>1.000329</td>\n      <td>-4.844773</td>\n      <td>-0.675401</td>\n      <td>-0.003064</td>\n      <td>0.674177</td>\n      <td>4.823084</td>\n    </tr>\n    <tr>\n      <th>f_07</th>\n      <td>720000.0</td>\n      <td>2.032101</td>\n      <td>1.656758</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>15.000000</td>\n    </tr>\n    <tr>\n      <th>f_08</th>\n      <td>720000.0</td>\n      <td>2.058133</td>\n      <td>1.589792</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>16.000000</td>\n    </tr>\n    <tr>\n      <th>f_09</th>\n      <td>720000.0</td>\n      <td>2.362396</td>\n      <td>1.638384</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>14.000000</td>\n    </tr>\n    <tr>\n      <th>f_10</th>\n      <td>720000.0</td>\n      <td>2.178393</td>\n      <td>1.647363</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>14.000000</td>\n    </tr>\n    <tr>\n      <th>f_11</th>\n      <td>720000.0</td>\n      <td>1.803815</td>\n      <td>1.536798</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>13.000000</td>\n    </tr>\n    <tr>\n      <th>f_12</th>\n      <td>720000.0</td>\n      <td>2.842792</td>\n      <td>1.762582</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>4.000000</td>\n      <td>16.000000</td>\n    </tr>\n    <tr>\n      <th>f_13</th>\n      <td>720000.0</td>\n      <td>2.239012</td>\n      <td>1.538853</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>12.000000</td>\n    </tr>\n    <tr>\n      <th>f_14</th>\n      <td>720000.0</td>\n      <td>1.515094</td>\n      <td>1.359418</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>14.000000</td>\n    </tr>\n    <tr>\n      <th>f_15</th>\n      <td>720000.0</td>\n      <td>2.100882</td>\n      <td>1.568964</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>14.000000</td>\n    </tr>\n    <tr>\n      <th>f_16</th>\n      <td>720000.0</td>\n      <td>2.095808</td>\n      <td>1.560076</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>14.000000</td>\n    </tr>\n    <tr>\n      <th>f_17</th>\n      <td>720000.0</td>\n      <td>1.859015</td>\n      <td>1.467834</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>14.000000</td>\n    </tr>\n    <tr>\n      <th>f_18</th>\n      <td>720000.0</td>\n      <td>2.063921</td>\n      <td>1.563454</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>13.000000</td>\n    </tr>\n    <tr>\n      <th>f_19</th>\n      <td>720000.0</td>\n      <td>0.000250</td>\n      <td>1.000247</td>\n      <td>-5.004879</td>\n      <td>-0.666936</td>\n      <td>0.010062</td>\n      <td>0.678778</td>\n      <td>5.083719</td>\n    </tr>\n    <tr>\n      <th>f_20</th>\n      <td>720000.0</td>\n      <td>-0.000600</td>\n      <td>1.000388</td>\n      <td>-4.618396</td>\n      <td>-0.677958</td>\n      <td>-0.005689</td>\n      <td>0.676017</td>\n      <td>4.856252</td>\n    </tr>\n    <tr>\n      <th>f_21</th>\n      <td>720000.0</td>\n      <td>-0.001178</td>\n      <td>1.000322</td>\n      <td>-5.294815</td>\n      <td>-0.671577</td>\n      <td>-0.000045</td>\n      <td>0.668177</td>\n      <td>5.880781</td>\n    </tr>\n    <tr>\n      <th>f_22</th>\n      <td>720000.0</td>\n      <td>-0.000726</td>\n      <td>0.999514</td>\n      <td>-4.833376</td>\n      <td>-0.667598</td>\n      <td>0.015394</td>\n      <td>0.679953</td>\n      <td>4.631773</td>\n    </tr>\n    <tr>\n      <th>f_23</th>\n      <td>720000.0</td>\n      <td>0.000729</td>\n      <td>1.000057</td>\n      <td>-4.835009</td>\n      <td>-0.672489</td>\n      <td>-0.008004</td>\n      <td>0.662473</td>\n      <td>5.143642</td>\n    </tr>\n    <tr>\n      <th>f_24</th>\n      <td>720000.0</td>\n      <td>-0.000332</td>\n      <td>0.999378</td>\n      <td>-4.637862</td>\n      <td>-0.675718</td>\n      <td>0.000694</td>\n      <td>0.673654</td>\n      <td>4.812514</td>\n    </tr>\n    <tr>\n      <th>f_25</th>\n      <td>720000.0</td>\n      <td>-0.000380</td>\n      <td>1.000008</td>\n      <td>-5.003208</td>\n      <td>-0.669041</td>\n      <td>-0.006302</td>\n      <td>0.669827</td>\n      <td>4.579917</td>\n    </tr>\n    <tr>\n      <th>f_26</th>\n      <td>720000.0</td>\n      <td>-0.000658</td>\n      <td>0.999808</td>\n      <td>-5.036366</td>\n      <td>-0.653386</td>\n      <td>0.018154</td>\n      <td>0.674503</td>\n      <td>5.069536</td>\n    </tr>\n    <tr>\n      <th>f_28</th>\n      <td>720000.0</td>\n      <td>-0.001669</td>\n      <td>0.999937</td>\n      <td>-5.149409</td>\n      <td>-0.667938</td>\n      <td>-0.002385</td>\n      <td>0.665618</td>\n      <td>5.148192</td>\n    </tr>\n    <tr>\n      <th>f_29</th>\n      <td>720000.0</td>\n      <td>0.345790</td>\n      <td>0.475626</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>f_30</th>\n      <td>720000.0</td>\n      <td>1.003101</td>\n      <td>0.819145</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>f_27_1</th>\n      <td>720000.0</td>\n      <td>0.498760</td>\n      <td>0.499999</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>f_27_2</th>\n      <td>720000.0</td>\n      <td>1.967406</td>\n      <td>1.500410</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>13.000000</td>\n    </tr>\n    <tr>\n      <th>f_27_3</th>\n      <td>720000.0</td>\n      <td>0.668911</td>\n      <td>0.470605</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>f_27_4</th>\n      <td>720000.0</td>\n      <td>1.988535</td>\n      <td>1.595156</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>14.000000</td>\n    </tr>\n    <tr>\n      <th>f_27_5</th>\n      <td>720000.0</td>\n      <td>1.386311</td>\n      <td>1.297445</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>14.000000</td>\n    </tr>\n    <tr>\n      <th>f_27_6</th>\n      <td>720000.0</td>\n      <td>0.467568</td>\n      <td>0.498947</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>f_27_7</th>\n      <td>720000.0</td>\n      <td>2.378196</td>\n      <td>1.656377</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>14.000000</td>\n    </tr>\n    <tr>\n      <th>f_27_8</th>\n      <td>720000.0</td>\n      <td>9.363194</td>\n      <td>5.704607</td>\n      <td>0.000000</td>\n      <td>4.000000</td>\n      <td>9.000000</td>\n      <td>14.000000</td>\n      <td>19.000000</td>\n    </tr>\n    <tr>\n      <th>f_27_9</th>\n      <td>720000.0</td>\n      <td>2.022092</td>\n      <td>1.600362</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>14.000000</td>\n    </tr>\n    <tr>\n      <th>f_27_10</th>\n      <td>720000.0</td>\n      <td>2.283601</td>\n      <td>1.652476</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>14.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 720000 entries, 94700 to 128037\nData columns (total 40 columns):\n #   Column   Non-Null Count   Dtype  \n---  ------   --------------   -----  \n 0   f_00     720000 non-null  float32\n 1   f_01     720000 non-null  float32\n 2   f_02     720000 non-null  float32\n 3   f_03     720000 non-null  float32\n 4   f_04     720000 non-null  float32\n 5   f_05     720000 non-null  float32\n 6   f_06     720000 non-null  float32\n 7   f_07     720000 non-null  int8   \n 8   f_08     720000 non-null  int8   \n 9   f_09     720000 non-null  int8   \n 10  f_10     720000 non-null  int8   \n 11  f_11     720000 non-null  int8   \n 12  f_12     720000 non-null  int8   \n 13  f_13     720000 non-null  int8   \n 14  f_14     720000 non-null  int8   \n 15  f_15     720000 non-null  int8   \n 16  f_16     720000 non-null  int8   \n 17  f_17     720000 non-null  int8   \n 18  f_18     720000 non-null  int8   \n 19  f_19     720000 non-null  float32\n 20  f_20     720000 non-null  float32\n 21  f_21     720000 non-null  float32\n 22  f_22     720000 non-null  float32\n 23  f_23     720000 non-null  float32\n 24  f_24     720000 non-null  float32\n 25  f_25     720000 non-null  float32\n 26  f_26     720000 non-null  float32\n 27  f_28     720000 non-null  float32\n 28  f_29     720000 non-null  int8   \n 29  f_30     720000 non-null  int8   \n 30  f_27_1   720000 non-null  int8   \n 31  f_27_2   720000 non-null  int8   \n 32  f_27_3   720000 non-null  int8   \n 33  f_27_4   720000 non-null  int8   \n 34  f_27_5   720000 non-null  int8   \n 35  f_27_6   720000 non-null  int8   \n 36  f_27_7   720000 non-null  int8   \n 37  f_27_8   720000 non-null  int8   \n 38  f_27_9   720000 non-null  int8   \n 39  f_27_10  720000 non-null  int8   \ndtypes: float32(16), int8(24)\nmemory usage: 65.9 MB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"None"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.linear_model import Perceptron\n\nperceptron_model = Perceptron(\n    eta0=0.1, # Learning rate of the model\n    random_state=1\n)\nperceptron_model.fit(\n    X_train,\n    y_train\n)\nperceptron_prediction = perceptron_model.predict(X_val)\nperceptron_accuracy = (perceptron_prediction==y_val).sum()/y_val.shape[0]\nprint(\"Perceptron model accuracy is : \", perceptron_accuracy)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:32:41.047785Z","iopub.execute_input":"2022-05-05T14:32:41.048578Z","iopub.status.idle":"2022-05-05T14:32:43.585076Z","shell.execute_reply.started":"2022-05-05T14:32:41.048515Z","shell.execute_reply":"2022-05-05T14:32:43.582590Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Perceptron model accuracy is :  0.5933277777777778\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nforest_model = RandomForestClassifier(\n    n_estimators=25, # Number of trees generated in the model\n    random_state=1,\n    n_jobs=2 # Making parallel computing by using 2 cores\n)\nforest_model.fit(X_train,y_train)\nforest_prediction = forest_model.predict(X_val)\nforest_accuracy = (forest_prediction == y_val).sum()/y_val.shape[0]\nprint(\"Random Forest model accuracy : \", forest_accuracy)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:32:43.587649Z","iopub.execute_input":"2022-05-05T14:32:43.587907Z","iopub.status.idle":"2022-05-05T14:34:16.184486Z","shell.execute_reply.started":"2022-05-05T14:32:43.587872Z","shell.execute_reply":"2022-05-05T14:34:16.183703Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Random Forest model accuracy :  0.8276444444444444\n","output_type":"stream"}]},{"cell_type":"code","source":"def nnmodel(inputs):\n    layer_activation = 'swish'\n    \n    layer_x = tf.keras.layers.Dense(32,name='dense_1',activation=layer_activation)(inputs)\n    layer_x = tf.keras.layers.Dropout(0.1)(layer_x)\n\n    layer_x = tf.keras.layers.Dense(32,name='dense_2',activation=layer_activation)(layer_x)\n    layer_x = tf.keras.layers.Dropout(0.1)(layer_x)\n\n    layer_x = tf.keras.layers.Dense(32,name='dense_3',activation=layer_activation)(layer_x)\n    layer_x = tf.keras.layers.Dropout(0.1)(layer_x)\n\n    layer_x = tf.keras.layers.Dense(32,name='dense_4',activation=layer_activation)(layer_x)\n    layer_x = tf.keras.layers.Dropout(0.1)(layer_x)\n\n    layer_x = tf.keras.layers.Dense(32,name='dense_5',activation=layer_activation)(layer_x)\n    layer_x = tf.keras.layers.Dropout(0.1)(layer_x)\n\n    layer_x = tf.keras.layers.Dense(32,name='dense_6',activation=layer_activation)(layer_x)\n    layer_x = tf.keras.layers.Dropout(0.1)(layer_x)\n\n    layer_x = tf.keras.layers.Dense(32,name='dense_7',activation=layer_activation)(layer_x)\n    layer_x = tf.keras.layers.Dropout(0.1)(layer_x)\n\n    layer_x = tf.keras.layers.Dense(32,name='dense_8',activation=layer_activation)(layer_x)\n    layer_x = tf.keras.layers.Dropout(0.1)(layer_x)\n    linear_reg_layer = tf.keras.layers.Dense(1,name='output_layer',activation='sigmoid')(layer_x)\n\n    model = tf.keras.Model(\n        inputs=inputs,\n        outputs=linear_reg_layer,\n        name='nn_model'\n    )\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:44:53.472752Z","iopub.execute_input":"2022-05-05T14:44:53.473009Z","iopub.status.idle":"2022-05-05T14:44:53.486823Z","shell.execute_reply.started":"2022-05-05T14:44:53.472982Z","shell.execute_reply":"2022-05-05T14:44:53.485973Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# train_tensor = tf.data.Dataset.from_tensor_slices((X_train,y_train))\n# val_tensor = tf.data.Dataset.from_tensor_slices((X_val,y_val))\n\n# BATCH_SIZE = 32\n# SHUFFLE_BUFFER_SIZE = 100\n\n# train_dataset = train_tensor.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n# val_dataset = val_tensor.batch(BATCH_SIZE)\n\n\ntf.keras.backend.clear_session()\n# # Acquiring a mirrored strategy to use multiple cores on GPU\n# strategy = tf.distribute.MultiWorkerMirroredStrategy()\n# BUFFER_SIZE = len(X_train)\n# BATCH_SIZE_PER_REPLICA = 32\n# GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\ntrain_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\nvalidation_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:44:54.643635Z","iopub.execute_input":"2022-05-05T14:44:54.643885Z","iopub.status.idle":"2022-05-05T14:44:55.022136Z","shell.execute_reply.started":"2022-05-05T14:44:54.643857Z","shell.execute_reply":"2022-05-05T14:44:55.021281Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"model = nnmodel(tf.keras.Input(shape=(X_train.shape[-1],)))\nmodel.compile(optimizer=tf.keras.optimizers.Adam(),\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\nmodel.fit(\n    train_dataset,\n    epochs=30,\n    validation_data=val_dataset\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:49:38.789510Z","iopub.execute_input":"2022-05-05T14:49:38.789860Z","iopub.status.idle":"2022-05-05T14:49:39.207070Z","shell.execute_reply.started":"2022-05-05T14:49:38.789817Z","shell.execute_reply":"2022-05-05T14:49:39.205758Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Epoch 1/30\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_33/2529006129.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m )\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    759\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 760\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /opt/conda/lib/python3.7/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/training.py:787 train_step\n        y_pred = self(x, training=True)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py:1037 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:415 call\n        inputs, training=training, mask=mask)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:550 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/input_spec.py:254 assert_input_compatibility\n        ' but received input with shape ' + display_shape(x.shape))\n\n    ValueError: Input 0 of layer dense_1 is incompatible with the layer: expected axis -1 of input shape to have value 40 but received input with shape (40, 1)\n"],"ename":"ValueError","evalue":"in user code:\n\n    /opt/conda/lib/python3.7/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/training.py:787 train_step\n        y_pred = self(x, training=True)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py:1037 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:415 call\n        inputs, training=training, mask=mask)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/functional.py:550 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /opt/conda/lib/python3.7/site-packages/keras/engine/input_spec.py:254 assert_input_compatibility\n        ' but received input with shape ' + display_shape(x.shape))\n\n    ValueError: Input 0 of layer dense_1 is incompatible with the layer: expected axis -1 of input shape to have value 40 but received input with shape (40, 1)\n","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}